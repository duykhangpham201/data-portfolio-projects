{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading datas from CryptoPredictor and StockPredictor files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "stock_model = tf.keras.models.load_model('stock_predict')\n",
    "crypto_model = tf.keras.models.load_model('crypto_predict')\n",
    "\n",
    "# Load Data\n",
    "df = pd.read_csv('predict_data.csv')\n",
    "stock_column = ['VN-Index', 'S&P 500', 'STOXX', 'VND/USD',\n",
    "                'VND/EUR', 'interest rate', 'inflation', 'GDP']\n",
    "crypto_column = ['SS', 'GSPC', 'N225', '^STOXX', 'Index']\n",
    "\n",
    "# Load Scaler\n",
    "stock_data_scaler = joblib.load('stock_data_scaler.save')\n",
    "crypto_data_scaler = joblib.load('crypto_data_scaler.save')\n",
    "stock_predict_scaler = joblib.load('stock_predict_scaler.save')\n",
    "crypto_predict_scaler = joblib.load('crypto_predict_scaler.save')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joining Savings, Stock, and Crypto data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n"
     ]
    }
   ],
   "source": [
    "# Transform Input Data\n",
    "stock_data = stock_data_scaler.transform(df[stock_column].values)\n",
    "crypto_data = crypto_data_scaler.transform(df[crypto_column].values)\n",
    "\n",
    "# Predict\n",
    "predicted_stock = stock_model.predict(np.reshape(\n",
    "    stock_data, (1, stock_data.shape[0], stock_data.shape[1])))\n",
    "predicted_stock = np.reshape(predicted_stock, (-1, 1))\n",
    "predicted_stock = stock_predict_scaler.inverse_transform(predicted_stock)\n",
    "\n",
    "predicted_crypto = crypto_model.predict(np.reshape(\n",
    "    crypto_data, (1, crypto_data.shape[0], crypto_data.shape[1])))\n",
    "predicted_crypto = np.reshape(predicted_crypto, (-1, 1))\n",
    "predicted_crypto = crypto_predict_scaler.inverse_transform(predicted_crypto)\n",
    "\n",
    "predicted_saving = df['Saving'][:40]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame for Portfolio Allocation\n",
    "df = pd.DataFrame(predicted_saving)\n",
    "df = df.join(pd.DataFrame(predicted_stock))\n",
    "df = df.join(pd.DataFrame(predicted_crypto), lsuffix='_left', rsuffix='_right')\n",
    "df.columns = ['Saving', 'VN-Index', 'Crypto']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modern Portfolio Theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_matrix = df.pct_change().apply(lambda x: np.log(1+x)).cov()\n",
    "corr_matrix = df.pct_change().apply(lambda x: np.log(1+x)).corr()\n",
    "ann_sd = df.pct_change().apply(lambda x: np.log(\n",
    "    1+x)).std().apply(lambda x: x*np.sqrt(250))\n",
    "ind_er = df.pct_change().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_ret = []  # Define an empty array for portfolio returns\n",
    "p_vol = []  # Define an empty array for portfolio volatility\n",
    "p_weights = []  # Define an empty array for asset weights\n",
    "\n",
    "num_assets = len(df.columns)\n",
    "num_portfolios = 10000\n",
    "\n",
    "for portfolio in range(num_portfolios):\n",
    "    weights = np.random.random(num_assets)\n",
    "    weights = weights/np.sum(weights)\n",
    "    p_weights.append(weights)\n",
    "    # Returns are the product of individual expected returns of asset and its weights\n",
    "    returns = np.dot(weights, ind_er)\n",
    "    p_ret.append(returns)\n",
    "\n",
    "    var = cov_matrix.mul(weights, axis=0).mul(\n",
    "        weights, axis=1).sum().sum()  # Portfolio Variance\n",
    "    sd = np.sqrt(var)  # Daily standard deviation\n",
    "    ann_sd = sd*np.sqrt(250)  # Annual standard deviation = volatility\n",
    "    p_vol.append(ann_sd)\n",
    "\n",
    "data = {'Returns': p_ret, 'Volatility': p_vol}\n",
    "\n",
    "for counter, symbol in enumerate(['savings', 'VN-Index', 'Crypto']):\n",
    "    data[symbol+' weight'] = [w[counter] for w in p_weights]\n",
    "\n",
    "portfolios = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Returns           -0.113863\n",
       "Volatility         1.643828\n",
       "savings weight     0.074540\n",
       "VN-Index weight    0.001084\n",
       "Crypto weight      0.924376\n",
       "Name: 9521, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the optimal portfolio\n",
    "rf = .05  # risk factor that could change based on investor's taste\n",
    "optimal_risky_port = portfolios.iloc[(\n",
    "    (portfolios['Returns']-rf)/portfolios['Volatility']).idxmax()]\n",
    "optimal_risky_port"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "69dc0ba6a52d390fabee0fd73bec981b8d2a1d9c72f6b9edb1d1ce733cad4a2c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
